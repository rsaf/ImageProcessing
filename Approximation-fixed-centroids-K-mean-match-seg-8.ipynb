{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage import data,color, exposure,feature,io\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.exposure as imexp\n",
    "from skimage.morphology import binary_opening,disk\n",
    "from skimage.filters import gabor_kernel\n",
    "from PIL import Image\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "(300, 300, 3)\n",
      "(100, 100, 3)\n",
      "(50, 50, 3)\n",
      "(100, 100, 3)\n",
      "(74, 59, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "imgSamples = [];\n",
    "imgHsvSamples = [];\n",
    "\n",
    "\n",
    "patches = [];\n",
    "patchesHsv = [];\n",
    "\n",
    "\n",
    "whitePatches = [];\n",
    "whitePatchesHsv = [];\n",
    "\n",
    "blackPatches = [];\n",
    "blackPatchesHsv = [];\n",
    "\n",
    "\n",
    "lesionPatches = [];\n",
    "lesionPatchesHsv = [];\n",
    "\n",
    "\n",
    "samplingSize =(300,300)\n",
    "#samplingMode = 'nearest'\n",
    "samplingMode = 'wrap'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,15):\n",
    "    imgSamples.append(resize(np.array(Image.open('newSamples/'+str(i+1)+'.jpg')), samplingSize,mode=samplingMode))\n",
    "                      \n",
    "for i in range(len(imgSamples)):\n",
    "    imgHsvSamples.append(color.rgb2hsv(imgSamples[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,2):\n",
    "    patches.append(np.array(Image.open('newPatches/normal'+str(i+1)+'.jpg')))\n",
    "                      \n",
    "for i in range(len(patches)):\n",
    "    patchesHsv.append(color.rgb2hsv(patches[i]))\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(0,1):\n",
    "    whitePatches.append(np.array(Image.open('newPatches/white'+str(i+1)+'.jpg')))\n",
    "                      \n",
    "for i in range(len(whitePatches)):\n",
    "    whitePatchesHsv.append(color.rgb2hsv(whitePatches[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,2):\n",
    "    blackPatches.append(np.array(Image.open('patches/black'+str(i+1)+'.jpg')))\n",
    "for i in range(len(blackPatches)):\n",
    "    blackPatchesHsv.append(color.rgb2hsv(blackPatches[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(0,4):\n",
    "    lesionPatches.append(np.array(Image.open('newPatches/lesion'+str(i+1)+'.jpg')))\n",
    "for i in range(len(lesionPatches)):\n",
    "    lesionPatchesHsv.append(color.rgb2hsv(lesionPatches[i]))\n",
    "\n",
    "\n",
    "print(len(imgHsvSamples))  \n",
    "print(len(patchesHsv)) \n",
    "print(len(whitePatchesHsv)) \n",
    "print(len(blackPatchesHsv)) \n",
    "print(len(lesionPatches)) \n",
    "print(imgHsvSamples[0].shape)\n",
    "print(patchesHsv[0].shape)\n",
    "print(whitePatchesHsv[0].shape)\n",
    "print(blackPatchesHsv[0].shape)\n",
    "print(lesionPatchesHsv[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def satThreshold(v,s):    ##return hue or intensity as dominant feature\n",
    "    th = 1.0 - 0.8*v;\n",
    "    if(s>th):\n",
    "        return \"h\"\n",
    "    else: \n",
    "        return \"v\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img):\n",
    "    tmpImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            dominantVal = satThreshold(img[i,j,2],img[i,j,1])\n",
    "#             print(\"dominantVal----\"+dominantVal)\n",
    "            tmpImg[i,j,:] = img[i,j,:]\n",
    "            if dominantVal == \"h\":\n",
    "                tmpImg[i,j,0] = img[i,j,0]\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = 1.0\n",
    "                \n",
    "            else:\n",
    "                tmpImg[i,j,0] = 1.0\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = img[i,j,2]\n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gabor filter\n",
    "\n",
    "def filterImage(image, kernels):\n",
    "    filtered = []\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered.append(ndi.convolve(image, kernel, mode='wrap'))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "    textTureFeatsLen = len(filteredImg)*3\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "#     merged_img = np.mean(filteredImg,axis=0)\n",
    "        \n",
    "#     for i in range(merged_img.shape[0]):\n",
    "#         for j in range(merged_img.shape[1]):\n",
    "#             window = merged_img[max(i-1,0):min(i+1,merged_img.shape[0]-1),max(j-1,0):min(j+1,merged_img.shape[1]-1)]\n",
    "\n",
    "#             feats[i,j, 0] = window.mean()\n",
    "#             feats[i,j, 1] = window.var()\n",
    "#             feats[i,j, 2] = merged_img[i,j]\n",
    "#             feats[i,j, 3] = hsvImg[i,j,0]\n",
    "#             feats[i,j, 4] = hsvImg[i,j,1]\n",
    "#             feats[i,j, 5] = hsvImg[i,j,2]\n",
    "#             feats[i,j, 6] = aprocHsvImg[i,j,0]\n",
    "#             feats[i,j, 7] = aprocHsvImg[i,j,1]\n",
    "#             feats[i,j, 8] = aprocHsvImg[i,j,2]\n",
    " \n",
    "#     return feats\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+3 == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+7] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += 3\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ref_img_feats():\n",
    "    \n",
    "#     print(\"ref images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "   \n",
    "    for i in range(len(patchesHsv)):\n",
    "        imgToFilter = rgb2gray(patches[i])\n",
    "        filtredImg =  filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = mass_compute_and_combine_feats(filtredImg,patchesHsv[i],approximate(patchesHsv[i]))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0) \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(ref_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ref_white_img_feats():\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(whitePatchesHsv)):\n",
    "        imgToFilter = rgb2gray(whitePatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = mass_compute_and_combine_feats(filtredImg,whitePatchesHsv[i],approximate(whitePatchesHsv[i]))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "\n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(ref_white_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ref_black_img_feats():\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(blackPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(blackPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = mass_compute_and_combine_feats(filtredImg,blackPatchesHsv[i],approximate(blackPatchesHsv[i]))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_lesion_img_feats():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(lesionPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(lesionPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = mass_compute_and_combine_feats(filtredImg,lesionPatchesHsv[i],approximate(lesionPatchesHsv[i]))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print ref_lesion_img_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###k-means for features\n",
    "\n",
    "\n",
    "####k-means class\n",
    "\n",
    "\n",
    "\n",
    "class K_Means_Feats:\n",
    "    def __init__(self, k=10, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.rgbColors = np.array([[0,255,0],[255,255,255],[0,0,0],[255,0,0],[0,0,255],[255,255,0],[0,255,255],[255,0,255],[51,51,255],[102,102,0],[255,0,127],[160,32,240],[238,130,238]])\n",
    "        self.rgbColors.astype(float)\n",
    "#        white, green, ,red, yellow, purple,violet\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit(self,img):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "\n",
    "        ref_feats_n = ref_feats_normal\n",
    "        ref_feats_w = ref_feats_white\n",
    "        ref_feats_b = ref_feats_black\n",
    "        ref_feats_l = ref_feats_lesion\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "#         print b_p_index\n",
    "        \n",
    "        #centroids for normal parts of the esophagus\n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "        #ramdomly select centroid for the lesions   \n",
    "#         self.centroids[self.k-1] = img[0,0,:]\n",
    "      \n",
    "        print(\"k----\")\n",
    "        print(self.k)\n",
    "        print(\"centroids----\")\n",
    "#         print(self.centroids)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1],3),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]:\n",
    "                \n",
    "                if  (cent < p_index): #normal pixels---assign green color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[0][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[0][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[0][2]\n",
    "                    \n",
    "                elif  (cent >= p_index) & (cent < w_p_index): #white pixels----assign white color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[1][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[1][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[1][2]\n",
    "                    \n",
    "                elif  (cent >= w_p_index) & (cent < b_p_index): # black pixels---assign black color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[2][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[2][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[2][2] \n",
    "                    \n",
    "                elif  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[3][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[3][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[3][2] \n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def fit_and_filter(self,img):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "\n",
    "        ref_feats_n = ref_feats_normal\n",
    "        ref_feats_w = ref_feats_white\n",
    "        ref_feats_b = ref_feats_black\n",
    "        ref_feats_l = ref_feats_lesion\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "        \n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "            \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1]),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]: \n",
    "                if  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1]] = 255\n",
    "                    \n",
    "        return binary_opening(binary_opening(output, disk(3)),disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing Gabor filter bank kernels\n",
    "kernels = []\n",
    "for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "    for sigma in (1.0,1.5):  #gausian kernel window size\n",
    "        for frequency in (0.1, 0.2):\n",
    "            kernel = np.real(gabor_kernel(frequency, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b0e5eb4b16a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mref_feats_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mref_feats_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_white_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mref_feats_black\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_black_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mref_feats_lesion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_lesion_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-4370e47b4e8a>\u001b[0m in \u001b[0;36mref_black_img_feats\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimgToFilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblackPatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfiltredImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgToFilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmass_compute_and_combine_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltredImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblackPatchesHsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblackPatchesHsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-846046ef1a7e>\u001b[0m in \u001b[0;36mmass_compute_and_combine_feats\u001b[0;34m(filteredImg, hsvImg, aprocHsvImg)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtextTureFeatsLen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rolland/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# not be either.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         arrmean = um.true_divide(\n\u001b[1;32m     94\u001b[0m                 arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##prepare reference features\n",
    "ref_feats_normal = ref_img_feats()\n",
    "ref_feats_white = ref_white_img_feats()\n",
    "ref_feats_black = ref_black_img_feats()\n",
    "ref_feats_lesion = ref_lesion_img_feats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##applying to imgSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filtredImg)\n",
      "24\n",
      "(300, 300)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-ba6fc18173d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeanf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmass_compute_and_combine_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltredImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHsvSamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapproximate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgHsvSamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"both \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-846046ef1a7e>\u001b[0m in \u001b[0;36mmass_compute_and_combine_feats\u001b[0;34m(filteredImg, hsvImg, aprocHsvImg)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtextTureFeatsLen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rolland/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "colnum = 4\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(imgSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lesionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(imgSamples[i])\n",
    "    \n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg)\")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i))\n",
    "    ax[index+1].axis('off')\n",
    "\n",
    "         \n",
    "    ax[index+2].imshow(kmeanf.fit(mass_compute_and_combine_feats(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i]))) ,cmap='gray')\n",
    "    ax[index+2].set_title(\"both \"+str(i))\n",
    "    ax[index+2].axis('off')\n",
    "    \n",
    "    ax[index+3].imshow(kmeanf.fit_and_filter(mass_compute_and_combine_feats(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i]))) ,cmap='gray')\n",
    "    ax[index+3].set_title(\"both \"+str(i))\n",
    "    ax[index+3].axis('off')\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
