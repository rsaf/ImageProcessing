{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage import data,color, exposure,feature,io\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.exposure as imexp\n",
    "from skimage.morphology import binary_opening,disk\n",
    "from skimage.filters import gabor_kernel\n",
    "from PIL import Image\n",
    "from skimage.exposure import rescale_intensity\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessImg(img):\n",
    "    gausssianSig = 0.4\n",
    "    \n",
    "    # Rescale image intensity so that we can see dim features.\n",
    "    image = img_as_float(img)\n",
    "    image = gaussian_filter(image,gausssianSig)\n",
    "#     image = rescale_intensity(image, in_range=(50, 200))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "(300, 300, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(74, 59, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imgSamples = [];\n",
    "imgHsvSamples = [];\n",
    "\n",
    "\n",
    "patches = [];\n",
    "patchesHsv = [];\n",
    "\n",
    "\n",
    "whitePatches = [];\n",
    "whitePatchesHsv = [];\n",
    "\n",
    "blackPatches = [];\n",
    "blackPatchesHsv = [];\n",
    "\n",
    "\n",
    "lesionPatches = [];\n",
    "lesionPatchesHsv = [];\n",
    "\n",
    "\n",
    "samplingSize =(300,300)\n",
    "#samplingMode = 'nearest'\n",
    "samplingMode = 'wrap'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,15):\n",
    "    imgSamples.append(preProcessImg(resize(np.array(Image.open('newSamples/'+str(i+1)+'.jpg')), samplingSize,mode=samplingMode)))\n",
    "                      \n",
    "for i in range(len(imgSamples)):\n",
    "    imgHsvSamples.append(color.rgb2hsv(imgSamples[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,2):\n",
    "    patches.append(preProcessImg(np.array(Image.open('newPatches2/normal'+str(i+1)+'.jpg'))))\n",
    "                      \n",
    "for i in range(len(patches)):\n",
    "    patchesHsv.append(color.rgb2hsv(patches[i]))\n",
    "    \n",
    "for i in range(0,1):\n",
    "    whitePatches.append(preProcessImg(np.array(Image.open('newPatches2/white'+str(i+1)+'.jpg'))))\n",
    "                      \n",
    "for i in range(len(whitePatches)):\n",
    "    whitePatchesHsv.append(color.rgb2hsv(whitePatches[i]))\n",
    "\n",
    "for i in range(0,2):\n",
    "    blackPatches.append(preProcessImg( np.array(Image.open('newPatches2/black'+str(i+1)+'.jpg'))))\n",
    "    \n",
    "for i in range(len(blackPatches)):\n",
    "    blackPatchesHsv.append(color.rgb2hsv(blackPatches[i]))\n",
    "    \n",
    "for i in range(0,7):\n",
    "    lesionPatches.append(preProcessImg(np.array(Image.open('newPatches2/lesion'+str(i+1)+'.jpg'))))\n",
    "    \n",
    "for i in range(len(lesionPatches)):\n",
    "    lesionPatchesHsv.append(color.rgb2hsv(lesionPatches[i]))\n",
    "\n",
    "\n",
    "print(len(imgHsvSamples))  \n",
    "print(len(patchesHsv)) \n",
    "print(len(whitePatchesHsv)) \n",
    "print(len(blackPatchesHsv)) \n",
    "print(len(lesionPatches)) \n",
    "print(imgHsvSamples[0].shape)\n",
    "print(patchesHsv[0].shape)\n",
    "# print(whitePatchesHsv[0].shape)\n",
    "print(blackPatchesHsv[0].shape)\n",
    "print(lesionPatchesHsv[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def satThreshold(v,s):    ##return hue or intensity as dominant feature\n",
    "    th = 1.0 - 0.8*v;\n",
    "    if(s>th):\n",
    "        return \"h\"\n",
    "    else: \n",
    "        return \"v\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img):\n",
    "    tmpImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            dominantVal = satThreshold(img[i,j,2],img[i,j,1])\n",
    "#             print(\"dominantVal----\"+dominantVal)\n",
    "            tmpImg[i,j,:] = img[i,j,:]\n",
    "            if dominantVal == \"h\":\n",
    "                tmpImg[i,j,0] = img[i,j,0]\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = 1.0\n",
    "                \n",
    "            else:\n",
    "                tmpImg[i,j,0] = 1.0\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = img[i,j,2]\n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gabor filter\n",
    "\n",
    "def filterImage(image, kernels):\n",
    "    filtered = []\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered.append(ndi.convolve(image, kernel, mode='wrap'))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+7] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats2(filteredImg,hsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats3(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats4(filteredImg,hsvImg,aprocHsvImg): #\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:   \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+7] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,2]       \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats5(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "    extractedFeats = 5\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                feats[i,j, step+3] = window.mean()\n",
    "                feats[i,j, step+4] = window.var()\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+5] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+6] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+7] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+9] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+10] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats6(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = 0\n",
    "#     textTureFeatsLen = len(filteredImg)*5\n",
    "    extractedFeats = 5\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    \n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                feats[i,j, step+3] = window.mean()\n",
    "                feats[i,j, step+4] = window.var()\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats7(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "    extractedFeats = 2\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "#                 feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+2] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+3] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats8(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "    extractedFeats = 4\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = np.sum(window**2)\n",
    "                feats[i,j, step+3] =  np.sum(np.absolute(window))\n",
    "#                 feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+5] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(ref_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(ref_white_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_img_feats(patchesName,which=1):\n",
    "    \n",
    "    \n",
    "    if patchesName == 'normal':   \n",
    "        targetImg = patches\n",
    "        targetImgHSV = patchesHsv\n",
    "    elif patchesName == 'white':\n",
    "        targetImg = whitePatches\n",
    "        targetImgHSV = whitePatchesHsv\n",
    "    elif patchesName == 'black':\n",
    "        targetImg = blackPatches\n",
    "        targetImgHSV = blackPatchesHsv\n",
    "    elif patchesName == 'lesion':\n",
    "        targetImg = lesionPatches\n",
    "        targetImgHSV = lesionPatchesHsv\n",
    "        \n",
    "    \n",
    "    ref_feats = {}\n",
    "\n",
    "    \n",
    "    for i in range(len(targetImgHSV)):\n",
    "        imgToFilter = rgb2gray(targetImg[i])\n",
    "        imgToFilter = rescale_intensity(imgToFilter, in_range=(0.4, 0.9))\n",
    "        filtredImg = filterImage(imgToFilter,kernels)    \n",
    "        \n",
    "        \n",
    "        if which ==1 :\n",
    "            ref_feats[i] = mass_compute_and_combine_feats(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "        elif which == 2:\n",
    "            ref_feats[i] =  mass_compute_and_combine_feats2(filtredImg,targetImgHSV[i])\n",
    "        elif which == 3:\n",
    "            ref_feats[i] =  mass_compute_and_combine_feats3(filtredImg,approximate(targetImgHSV[i]))\n",
    "        elif which == 4:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats4(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "\n",
    "        elif which == 5:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats5(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "\n",
    "        elif which == 6:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats6(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "        elif which == 7:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats7(filtredImg,approximate(targetImgHSV[i]))\n",
    "        \n",
    "        elif which == 8:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats8(filtredImg,approximate(targetImgHSV[i]))\n",
    "            \n",
    "            \n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###k-means for features\n",
    "\n",
    "\n",
    "####k-means class\n",
    "\n",
    "\n",
    "\n",
    "class K_Means_Feats:\n",
    "    def __init__(self, k=10, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.rgbColors = np.array([[0,255,0],[255,255,255],[0,0,0],[255,0,0],[0,0,255],[255,255,0],[0,255,255],[255,0,255],[51,51,255],[102,102,0],[255,0,127],[160,32,240],[238,130,238]])\n",
    "        self.rgbColors.astype(float)\n",
    "#        white, green, ,red, yellow, purple,violet\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit(self,img,which=1):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ref_feats_n = ref_feats_dict[which-1][0]\n",
    "        ref_feats_w = ref_feats_dict[which-1][1]\n",
    "        ref_feats_b = ref_feats_dict[which-1][2]\n",
    "        ref_feats_l = ref_feats_dict[which-1][3]\n",
    "        \n",
    "        \n",
    "        #centroids for normal parts of the esophagus\n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "        #ramdomly select centroid for the lesions   \n",
    "#         self.centroids[self.k-1] = img[0,0,:]\n",
    "      \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1],3),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]:\n",
    "                \n",
    "                if  (cent < p_index): #normal pixels---assign green color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[0][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[0][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[0][2]\n",
    "                    \n",
    "                elif  (cent >= p_index) & (cent < w_p_index): #white pixels----assign white color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[1][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[1][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[1][2]\n",
    "                    \n",
    "                elif  (cent >= w_p_index) & (cent < b_p_index): # black pixels---assign black color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[2][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[2][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[2][2] \n",
    "                    \n",
    "                elif  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[3][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[3][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[3][2] \n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_and_filter(self,img):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "\n",
    "        ref_feats_n = ref_feats_normal\n",
    "        ref_feats_w = ref_feats_white\n",
    "        ref_feats_b = ref_feats_black\n",
    "        ref_feats_l = ref_feats_lesion\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "        \n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "            \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1]),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]: \n",
    "                if  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1]] = 255\n",
    "                    \n",
    "        return binary_opening(binary_opening(output, disk(3)),disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing Gabor filter bank kernels\n",
    "kernels = []\n",
    "for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "    for sigma in (1.0,1.5):  #gausian kernel window size\n",
    "#         for frequency in (0.1, 0.2):\n",
    "            kernel = np.real(gabor_kernel(0.15, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'rescale_intensity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-ccd1af1f3379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-109617062bac>\u001b[0m in \u001b[0;36mref_img_feats\u001b[0;34m(patchesName, which)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetImgHSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimgToFilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimgToFilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescale_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgToFilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mfiltredImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgToFilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'rescale_intensity' is not defined"
     ]
    }
   ],
   "source": [
    "##prepare reference features\n",
    "ref_feats_dict = {}\n",
    "\n",
    "for i in range(8):\n",
    "    ref_feats_dict[i]=[]\n",
    "    ref_feats_dict[i].append(ref_img_feats('normal',which=i+1))\n",
    "    ref_feats_dict[i].append(ref_img_feats('white',which=i+1))\n",
    "    ref_feats_dict[i].append(ref_img_feats('black',which=i+1))\n",
    "    ref_feats_dict[i].append(ref_img_feats('lesion',which=i+1))\n",
    "    print i\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Best working ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colnum = 6\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(imgSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*20), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lesionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(imgSamples[i])\n",
    "    imgToFilter = rescale_intensity(imgToFilter, in_range=(0.4, 0.9))\n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg) \")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i))\n",
    "    ax[index+1].axis('off')\n",
    "\n",
    "         \n",
    "    ax[index+2].imshow(kmeanf.fit(mass_compute_and_combine_feats(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=1) ,cmap='gray')\n",
    "    ax[index+2].set_title(\"both \"+str(i))\n",
    "    ax[index+2].axis('off')\n",
    "    \n",
    "    ax[index+3].imshow(kmeanf.fit(mass_compute_and_combine_feats7(filtredImg,imgHsvSamples[i]),which=7) ,cmap='gray')\n",
    "    ax[index+3].set_title(\"both \"+str(i))\n",
    "    ax[index+3].axis('off')\n",
    "    \n",
    "    \n",
    "    ax[index+4].imshow(kmeanf.fit(mass_compute_and_combine_feats3(filtredImg,approximate(imgHsvSamples[i])),which=3) ,cmap='gray')\n",
    "    ax[index+4].set_title(\"both \"+str(i))\n",
    "    ax[index+4].axis('off')\n",
    "    \n",
    "    ax[index+5].imshow(kmeanf.fit(mass_compute_and_combine_feats8(filtredImg,approximate(imgHsvSamples[i])),which=8) ,cmap='gray')\n",
    "    ax[index+5].set_title(\"both \"+str(i))\n",
    "    ax[index+5].axis('off')\n",
    "    \n",
    "    print \"img \"+str(i)+\"----done\"\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"the longger one is on-------->>>>------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnum = 8\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(imgSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lesionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(imgSamples[i])\n",
    "    imgToFilter = rescale_intensity(imgToFilter, in_range=(0.4, 0.9))\n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg) \")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i))\n",
    "    ax[index+1].axis('off')\n",
    "\n",
    "         \n",
    "    ax[index+2].imshow(kmeanf.fit(mass_compute_and_combine_feats(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=1) ,cmap='gray')\n",
    "    ax[index+2].set_title(\"both \"+str(i))\n",
    "    ax[index+2].axis('off')\n",
    "    \n",
    "    ax[index+3].imshow(kmeanf.fit(mass_compute_and_combine_feats2(filtredImg,imgHsvSamples[i]),which=2) ,cmap='gray')\n",
    "    ax[index+3].set_title(\"both \"+str(i))\n",
    "    ax[index+3].axis('off')\n",
    "    \n",
    "    \n",
    "    ax[index+4].imshow(kmeanf.fit(mass_compute_and_combine_feats3(filtredImg,approximate(imgHsvSamples[i])),which=3) ,cmap='gray')\n",
    "    ax[index+4].set_title(\"both \"+str(i))\n",
    "    ax[index+4].axis('off')\n",
    "    \n",
    "    ax[index+5].imshow(kmeanf.fit(mass_compute_and_combine_feats4(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=4) ,cmap='gray')\n",
    "    ax[index+5].set_title(\"both \"+str(i))\n",
    "    ax[index+5].axis('off')\n",
    "    \n",
    "    \n",
    "    ax[index+6].imshow(kmeanf.fit(mass_compute_and_combine_feats5(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=5) ,cmap='gray')\n",
    "    ax[index+6].set_title(\"both \"+str(i))\n",
    "    ax[index+6].axis('off')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax[index+7].imshow(kmeanf.fit(mass_compute_and_combine_feats6(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=6) ,cmap='gray')\n",
    "    ax[index+7].set_title(\"both \"+str(i))\n",
    "    ax[index+7].axis('off')\n",
    "    \n",
    "    print \"img \"+str(i)+\"----done\"\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
