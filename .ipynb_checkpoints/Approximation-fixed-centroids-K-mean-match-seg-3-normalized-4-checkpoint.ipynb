{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import data,color, exposure,feature,io,img_as_float\n",
    "from math import sqrt\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.exposure as imexp\n",
    "from skimage.filters import gabor_kernel\n",
    "from PIL import Image\n",
    "from scipy import ndimage as ndi\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-e54dc2f947d2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e54dc2f947d2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def (image):\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def equalize_hist_each(image):\n",
    "    return exposure.equalize_hist(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "onlineSamples = []\n",
    "onlineHsvSamples = []\n",
    "\n",
    "imgSamples = [];\n",
    "imgHsvSamples = [];\n",
    "\n",
    "\n",
    "patches = [];\n",
    "patchesHsv = [];\n",
    "\n",
    "\n",
    "whitePatches = [];\n",
    "whitePatchesHsv = [];\n",
    "\n",
    "blackPatches = [];\n",
    "blackPatchesHsv = [];\n",
    "\n",
    "\n",
    "lessionPatches = [];\n",
    "lessionPatchesHsv = [];\n",
    "\n",
    "\n",
    "samplingSize =(300,300)\n",
    "#samplingMode = 'nearest'\n",
    "samplingMode = 'wrap'\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    onlineSamples.append(equalize_hist_each(resize(np.array(Image.open('onlineSamples/textures/'+str(i+1)+'.jpg')),samplingSize,mode=samplingMode)))\n",
    "                      \n",
    "for i in range(0,3):\n",
    "    onlineHsvSamples.append(color.rgb2hsv(onlineSamples[i]))\n",
    "\n",
    "for i in range(0,5):\n",
    "    imgSamples.append(equalize_hist_each(resize(np.array(Image.open('samples_croped/'+str(i+1)+'.jpg')), samplingSize,mode=samplingMode)))\n",
    "                      \n",
    "for i in range(0,5):\n",
    "    imgHsvSamples.append(color.rgb2hsv(imgSamples[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,5):\n",
    "    patches.append(equalize_hist_each(np.array(Image.open('patches/'+str(i+1)+'.jpg'))))\n",
    "                      \n",
    "for i in range(0,5):\n",
    "    patchesHsv.append(color.rgb2hsv(patches[i]))\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(0,3):\n",
    "    whitePatches.append(equalize_hist_each(np.array(Image.open('patches/white'+str(i+1)+'.jpg'))))\n",
    "                      \n",
    "for i in range(0,3):\n",
    "    whitePatchesHsv.append(color.rgb2hsv(whitePatches[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,4):\n",
    "    blackPatches.append(equalize_hist_each(np.array(Image.open('patches/black'+str(i+1)+'.jpg'))))\n",
    "for i in range(0,4):\n",
    "    blackPatchesHsv.append(color.rgb2hsv(blackPatches[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(0,9):\n",
    "    lessionPatches.append(equalize_hist_each(np.array(Image.open('patches/lession'+str(i+1)+'.jpg'))))\n",
    "for i in range(0,9):\n",
    "    lessionPatchesHsv.append(color.rgb2hsv(lessionPatches[i]))\n",
    "\n",
    "\n",
    "print(len(imgHsvSamples))  \n",
    "print(len(onlineHsvSamples)) \n",
    "print(len(patchesHsv)) \n",
    "print(len(whitePatchesHsv)) \n",
    "print(len(blackPatchesHsv)) \n",
    "print(len(lessionPatches)) \n",
    "print(imgHsvSamples[0].shape)\n",
    "print(onlineHsvSamples[0].shape)\n",
    "print(patchesHsv[0].shape)\n",
    "print(whitePatchesHsv[0].shape)\n",
    "print(blackPatchesHsv[0].shape)\n",
    "print(lessionPatchesHsv[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def satThreshold(v,s):    ##return hue or intensity as dominant feature\n",
    "    th = 1.0 - 0.8*v;\n",
    "    if(s>th):\n",
    "        return \"h\"\n",
    "    else: \n",
    "        return \"v\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img):\n",
    "    tmpImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            dominantVal = satThreshold(img[i,j,2],img[i,j,1])\n",
    "#             print(\"dominantVal----\"+dominantVal)\n",
    "            tmpImg[i,j,:] = img[i,j,:]\n",
    "            if dominantVal == \"h\":\n",
    "                tmpImg[i,j,0] = img[i,j,0]\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = 1.0\n",
    "                \n",
    "            else:\n",
    "                tmpImg[i,j,0] = 1.0\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = img[i,j,2]\n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ploating online samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##extrac main component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractMainComp(approx_img):\n",
    "    #0.12 green , #0.67 blue , #0,1 red\n",
    "      return ( (approx_img[:,:,0] < 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractMainHsvComp(approx_img,hsv_img):\n",
    "    \n",
    "    tmpImg = np.zeros(hsv_img.shape)\n",
    "    for i in range(hsv_img.shape[0]):\n",
    "        for j in range(hsv_img.shape[1]):\n",
    "            tmpImg[i,j,:] = hsv_img[i,j,:]\n",
    "            if  not approx_img[i,j]: #turn to black\n",
    "                tmpImg[i,j,0] = 0.\n",
    "                tmpImg[i,j,1] = 0.\n",
    "                tmpImg[i,j,2] = 0.      \n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##extract main hsv component based on approximated image result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gabor filter\n",
    "\n",
    "\n",
    "def filterImage(image, kernels):\n",
    "    feats = np.zeros((len(kernels), 2),np.uint8)\n",
    "    filtered = []\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered.append(ndi.convolve(image, kernel, mode='wrap'))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_feats(image):\n",
    "    feats = np.zeros((image.shape[0],image.shape[1],2),np.uint8)\n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "            feats[i,j, 0] = window.mean()\n",
    "            feats[i,j, 1] = window.var()\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_feats(images):\n",
    "    feats = np.zeros((images[0].shape[0],images[0].shape[1],2*len(images)))\n",
    "    feat_index = 0;\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "       \n",
    "                feats[i,j, feat_index] = window.mean()\n",
    "                feats[i,j, feat_index+1] = window.var()\n",
    "                \n",
    "        feat_index+=2\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_feats2(images):\n",
    "    feats = np.zeros((images[0].shape[0],images[0].shape[1],len(images)))\n",
    "    \n",
    "    for k in range(len(images)):\n",
    "        for i in range(images[k].shape[0]):\n",
    "            for j in range(images[k].shape[1]):\n",
    "                \n",
    "                feats[i,j, k] = images[k][i,j]\n",
    "        \n",
    "#     print(\"images[0].shape[0]----\",images[0].shape[0])   \n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_feats3(images):\n",
    "    feats = np.zeros((images[0].shape[0],images[0].shape[1],2*len(images)))\n",
    "    \n",
    "    \n",
    "    for k in range(len(images)):\n",
    "        for i in range(images[k].shape[0]):\n",
    "            for j in range(images[k].shape[1]):\n",
    "                window = images[k][max(i-1,0):min(i+1,images[k].shape[0]-1),max(j-1,0):min(j+1,images[k].shape[1]-1)]\n",
    "                \n",
    "                feats[i,j, 2*k] = np.sum(np.square(window))\n",
    "                feats[i,j, 2*k+1] = np.sum(window)\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_color_feats(hsvImg,grayScaleFeats):\n",
    "    newDim =  grayScaleFeats.shape[2]+3\n",
    "    newFeats = np.zeros((hsvImg.shape[0],hsvImg.shape[1],newDim))\n",
    "    \n",
    "    for k in range(grayScaleFeats.shape[0]):\n",
    "        for l in range(grayScaleFeats.shape[1]):\n",
    "            for h in range(grayScaleFeats.shape[2]):\n",
    "                newFeats[k,l,h] = grayScaleFeats[k,l,h]\n",
    "#                 print(newFeats[k,l,h])\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]] = hsvImg[k,l,0]\n",
    "#             print(newFeats[k,l,newDim-3])\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+1] = hsvImg[k,l,1]\n",
    "#             print(newFeats[k,l,newDim-2])\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+2] = hsvImg[k,l,2]\n",
    " \n",
    "    return newFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_color_feats2(hsvImg,aprocHsvImg,grayScaleFeats):\n",
    "    newDim =  grayScaleFeats.shape[2]+6\n",
    "    newFeats = np.zeros((hsvImg.shape[0],hsvImg.shape[1],newDim))\n",
    "    \n",
    "    for k in range(grayScaleFeats.shape[0]):\n",
    "        for l in range(grayScaleFeats.shape[1]):\n",
    "            for h in range(grayScaleFeats.shape[2]):\n",
    "                newFeats[k,l,h] = grayScaleFeats[k,l,h]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]] = hsvImg[k,l,0]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+1] = hsvImg[k,l,1]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+2] = hsvImg[k,l,2]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+3] = aprocHsvImg[k,l,0]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+4] = aprocHsvImg[k,l,1]\n",
    "            newFeats[k,l,grayScaleFeats.shape[2]+5] = aprocHsvImg[k,l,2]\n",
    "\n",
    " \n",
    "    return newFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def ref_img_feats():\n",
    "    \n",
    "#     print(\"ref images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "#     print(\"patchesHsv[0]\")\n",
    "#     print(patchesHsv[0].shape)\n",
    "#     print(patchesHsv[0])\n",
    "\n",
    "   \n",
    "    for i in range(len(patchesHsv)):\n",
    "        imgToFilter = rgb2gray(patches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats(patchesHsv[i],mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('ref_feats[i]------arranged---')\n",
    "#     print ref_feats[0][0]\n",
    "        \n",
    "    return ref_feats\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ref_img_feats2():\n",
    "    \n",
    "#     print(\"ref images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "#     print(\"patchesHsv[0]\")\n",
    "#     print(patchesHsv[0].shape)\n",
    "#     print(patchesHsv[0])\n",
    "\n",
    "   \n",
    "    for i in range(len(patchesHsv)):\n",
    "        imgToFilter = rgb2gray(patches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats2(patchesHsv[i],approximate(patchesHsv[i]),mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('ref_feats[i]------arranged---')\n",
    "#     print ref_feats[0][0]\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(ref_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_white_img_feats():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "#     print(whitePatchesHsv[0].shape)\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(whitePatchesHsv)):\n",
    "        imgToFilter = rgb2gray(whitePatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats(whitePatchesHsv[i],mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('white ref_feats[i]------arranged---')\n",
    "#     print ref_feats\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ref_white_img_feats2():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "#     print(whitePatchesHsv[0].shape)\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(whitePatchesHsv)):\n",
    "        imgToFilter = rgb2gray(whitePatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats2(whitePatchesHsv[i],approximate(whitePatchesHsv[i]),mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('white ref_feats[i]------arranged---')\n",
    "#     print ref_feats\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(ref_white_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ref_black_img_feats():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(blackPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(blackPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats(blackPatchesHsv[i],mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('black ref_feats[i]------arranged---')\n",
    "#     print ref_feats[0][0]\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ref_black_img_feats2():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(blackPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(blackPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats2(blackPatchesHsv[i],approximate(blackPatchesHsv[i]),mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print('black ref_feats[i]------arranged---')\n",
    "#     print ref_feats[0][0]\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_lession_img_feats():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(lessionPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(lessionPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats(lessionPatchesHsv[i],mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_lession_img_feats2():\n",
    "    \n",
    "#     print(\"ref white images features\")\n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    for i in range(len(lessionPatchesHsv)):\n",
    "        imgToFilter = rgb2gray(lessionPatches[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)\n",
    "        ref_feats[i] = add_color_feats2(lessionPatchesHsv[i],approximate(lessionPatchesHsv[i]),mass_compute_feats(filtredImg))\n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print ref_lession_img_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###k-means for features\n",
    "\n",
    "\n",
    "####k-means class\n",
    "\n",
    "\n",
    "\n",
    "class K_Means_Feats:\n",
    "    def __init__(self, k=10, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.rgbColors = np.array([[0,255,0],[255,255,255],[0,0,0],[255,0,0],[0,0,255],[255,255,0],[0,255,255],[255,0,255],[51,51,255],[102,102,0],[255,0,127],[160,32,240],[238,130,238]])\n",
    "        self.rgbColors.astype(float)\n",
    "#        white, green, ,red, yellow, purple,violet\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit(self,img,mode='1'):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "        \n",
    "        if mode == '2':\n",
    "            print(\"mode 2\")\n",
    "            ref_feats_n = ref_feats_normal2\n",
    "            ref_feats_w = ref_feats_white2\n",
    "            ref_feats_b = ref_feats_black2\n",
    "            ref_feats_l = ref_feats_lession2\n",
    "        else:\n",
    "            \n",
    "            ref_feats_n = ref_feats_normal\n",
    "            ref_feats_w = ref_feats_white\n",
    "            ref_feats_b = ref_feats_black\n",
    "            ref_feats_l = ref_feats_lession\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "#         print b_p_index\n",
    "        \n",
    "        #centroids for normal parts of the esophagus\n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lessionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "        #ramdomly select centroid for the lessions   \n",
    "#         self.centroids[self.k-1] = img[0,0,:]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "      \n",
    "        print(\"k----\")\n",
    "        print(self.k)\n",
    "        print(\"centroids----\")\n",
    "#         print(self.centroids)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1],3),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]:\n",
    "                \n",
    "                \n",
    "                if  (cent < p_index): #normal pixels\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[0][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[0][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[0][2]\n",
    "                    \n",
    "                elif  (cent >= p_index) & (cent < w_p_index): #white pixels\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[1][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[1][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[1][2]\n",
    "                    \n",
    "                elif  (cent >= w_p_index) & (cent < b_p_index): # black pixels\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[2][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[2][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[2][2] \n",
    "                    \n",
    "                elif  (cent >= b_p_index): #lessions\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[3][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[3][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[3][2] \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "             \n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # prepare filter bank kernels\n",
    "# kernels = []\n",
    "\n",
    "# for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "#     for sigma in (1.0,1.25,1.5):  #gausian kernel window size\n",
    "#         for frequency in (0.1, 0.2):\n",
    "# #              0 < FL(i) < 0.25 and 0.25 ≤ FH (i) < 0.5.\n",
    "#             kernel = np.real(gabor_kernel(frequency, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "#             kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare filter bank kernels\n",
    "kernels = []\n",
    "\n",
    "for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "    for sigma in (1.0,1.5):  #gausian kernel window size\n",
    "        for frequency in (0.1, 0.2):\n",
    "#              0 < FL(i) < 0.25 and 0.25 ≤ FH (i) < 0.5.\n",
    "            kernel = np.real(gabor_kernel(frequency, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ##prepare reference features\n",
    "ref_feats_normal = ref_img_feats()\n",
    "ref_feats_white = ref_white_img_feats()\n",
    "ref_feats_black = ref_black_img_feats()\n",
    "ref_feats_lession = ref_lession_img_feats()\n",
    "    \n",
    "ref_feats_normal2 = ref_img_feats2()\n",
    "ref_feats_white2 = ref_white_img_feats2()\n",
    "ref_feats_black2 = ref_black_img_feats2()\n",
    "ref_feats_lession2 = ref_lession_img_feats2() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###applying to online samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colnum = 5\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(onlineSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lessionPatches))\n",
    "\n",
    "for i in range(0, len(onlineHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(onlineSamples[i])\n",
    "    \n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg)\")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(onlineSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(onlineHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i))\n",
    "    ax[index+1].axis('off')\n",
    "    \n",
    "    ax[index+2].imshow(kmeanf.fit(add_color_feats(approximate(onlineHsvSamples[i]),mass_compute_feats(filtredImg))),cmap='gray')\n",
    "    ax[index+2].set_title(\"apox \"+str(i))\n",
    "    ax[index+2].axis('off') \n",
    "\n",
    "    \n",
    "    ax[index+3].imshow(kmeanf.fit(add_color_feats(onlineHsvSamples[i],mass_compute_feats(filtredImg))) ,cmap='gray')\n",
    "    ax[index+3].set_title(\"hsv \"+str(i))\n",
    "    ax[index+3].axis('off')\n",
    "    \n",
    "     \n",
    "    ax[index+4].imshow(kmeanf.fit(add_color_feats2(onlineHsvSamples[i],approximate(onlineHsvSamples[i]),mass_compute_feats(filtredImg)),'2') ,cmap='gray')\n",
    "    ax[index+4].set_title(\"both \"+str(i))\n",
    "    ax[index+4].axis('off')\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##applying to imgSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colnum = 4\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(imgSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*10), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lessionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(imgSamples[i])\n",
    "    \n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg)\")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "    \n",
    "    ax[index+1].imshow(imgToFilter,cmap='gray')\n",
    "    ax[index+1].set_title(\"original \"+str(i))\n",
    "    ax[index+1].axis('off')  \n",
    "    \n",
    "    ax[index+2].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+2].set_title(\"segmented \"+str(i))\n",
    "    ax[index+2].axis('off')\n",
    "    \n",
    "    ax[index+3].imshow(kmeanf.fit(add_color_feats2(imgHsvSamples[i],approximate(imgHsvSamples[i]),mass_compute_feats(filtredImg)),'2') ,cmap='gray')\n",
    "    ax[index+3].set_title(\"segmented \"+str(i))\n",
    "    ax[index+3].axis('off')\n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
