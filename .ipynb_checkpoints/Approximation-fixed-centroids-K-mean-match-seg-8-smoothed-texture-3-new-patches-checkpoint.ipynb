{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage import data,color, exposure,feature,io\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.exposure as imexp\n",
    "from skimage.morphology import binary_opening,disk\n",
    "from skimage.filters import gabor_kernel\n",
    "from PIL import Image\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "(300, 300, 3)\n",
      "(100, 100, 3)\n",
      "(50, 50, 3)\n",
      "(100, 100, 3)\n",
      "(74, 59, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "imgSamples = [];\n",
    "imgHsvSamples = [];\n",
    "\n",
    "\n",
    "patches = [];\n",
    "patchesHsv = [];\n",
    "\n",
    "\n",
    "whitePatches = [];\n",
    "whitePatchesHsv = [];\n",
    "\n",
    "blackPatches = [];\n",
    "blackPatchesHsv = [];\n",
    "\n",
    "\n",
    "lesionPatches = [];\n",
    "lesionPatchesHsv = [];\n",
    "\n",
    "\n",
    "samplingSize =(300,300)\n",
    "#samplingMode = 'nearest'\n",
    "samplingMode = 'wrap'\n",
    "gausssianSig = 0.4\n",
    "\n",
    "\n",
    "texture_feats_names = ['var','mean','energy','amplitude']\n",
    "color_feats_names = ['hsv','approx-hsv']\n",
    "\n",
    "\n",
    "for i in range(0,15):\n",
    "    temp1= resize(np.array(Image.open('newSamples/'+str(i+1)+'.jpg')), samplingSize,mode=samplingMode)\n",
    "    image1 = img_as_float(temp1)\n",
    "    image1 = gaussian_filter(image1,gausssianSig)\n",
    "    imgSamples.append(image1)\n",
    "                      \n",
    "for i in range(len(imgSamples)):\n",
    "    imgHsvSamples.append(color.rgb2hsv(imgSamples[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,2):\n",
    "    \n",
    "    temp2= np.array(Image.open('newPatches3/normal'+str(i+1)+'.jpg'))\n",
    "    image2 = img_as_float(temp2)\n",
    "    image2 = gaussian_filter(image2, gausssianSig)\n",
    "    patches.append(image2)\n",
    "                      \n",
    "for i in range(len(patches)):\n",
    "    patchesHsv.append(color.rgb2hsv(patches[i]))\n",
    "    \n",
    "for i in range(0,1):\n",
    "    \n",
    "        \n",
    "    temp3= np.array(Image.open('newPatches3/white'+str(i+1)+'.jpg'))\n",
    "    image3 = img_as_float(temp3)\n",
    "    image3 = gaussian_filter(image3, gausssianSig)\n",
    "    whitePatches.append(image3)\n",
    "                      \n",
    "for i in range(len(whitePatches)):\n",
    "    whitePatchesHsv.append(color.rgb2hsv(whitePatches[i]))\n",
    "\n",
    "for i in range(0,2):\n",
    "    \n",
    "    temp4= np.array(Image.open('newPatches3/black'+str(i+1)+'.jpg'))\n",
    "    image4 = img_as_float(temp4)\n",
    "    image4 = gaussian_filter(image4,gausssianSig)\n",
    "    blackPatches.append(image4)\n",
    "    \n",
    "for i in range(len(blackPatches)):\n",
    "    blackPatchesHsv.append(color.rgb2hsv(blackPatches[i]))\n",
    "    \n",
    "for i in range(0,5):\n",
    "    \n",
    "    temp5=np.array(Image.open('newPatches3/lesion'+str(i+1)+'.jpg'))\n",
    "    image5 = img_as_float(temp5)\n",
    "    image5 = gaussian_filter(image5, gausssianSig)\n",
    "    lesionPatches.append(temp5)\n",
    "    \n",
    "for i in range(len(lesionPatches)):\n",
    "    lesionPatchesHsv.append(color.rgb2hsv(lesionPatches[i]))\n",
    "\n",
    "\n",
    "print(len(imgHsvSamples))  \n",
    "print(len(patchesHsv)) \n",
    "print(len(whitePatchesHsv)) \n",
    "print(len(blackPatchesHsv)) \n",
    "print(len(lesionPatches)) \n",
    "print(imgHsvSamples[0].shape)\n",
    "print(patchesHsv[0].shape)\n",
    "print(whitePatchesHsv[0].shape)\n",
    "print(blackPatchesHsv[0].shape)\n",
    "print(lesionPatchesHsv[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def satThreshold(v,s):    ##return hue or intensity as dominant feature\n",
    "    th = 1.0 - 0.8*v;\n",
    "    if(s>th):\n",
    "        return \"h\"\n",
    "    else: \n",
    "        return \"v\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img):\n",
    "    tmpImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            dominantVal = satThreshold(img[i,j,2],img[i,j,1])\n",
    "#             print(\"dominantVal----\"+dominantVal)\n",
    "            tmpImg[i,j,:] = img[i,j,:]\n",
    "            if dominantVal == \"h\":\n",
    "                tmpImg[i,j,0] = img[i,j,0]\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = 1.0\n",
    "                \n",
    "            else:\n",
    "                tmpImg[i,j,0] = 1.0\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = img[i,j,2]\n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gabor filter\n",
    "\n",
    "def filterImage(image, kernels):\n",
    "    filtered = []\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered.append(ndi.convolve(image, kernel, mode='wrap'))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "#     merged_img = np.mean(filteredImg,axis=0)\n",
    "        \n",
    "#     for i in range(merged_img.shape[0]):\n",
    "#         for j in range(merged_img.shape[1]):\n",
    "#             window = merged_img[max(i-1,0):min(i+1,merged_img.shape[0]-1),max(j-1,0):min(j+1,merged_img.shape[1]-1)]\n",
    "\n",
    "#             feats[i,j, 0] = window.mean()\n",
    "#             feats[i,j, 1] = window.var()\n",
    "#             feats[i,j, 2] = merged_img[i,j]\n",
    "#             feats[i,j, 3] = hsvImg[i,j,0]\n",
    "#             feats[i,j, 4] = hsvImg[i,j,1]\n",
    "#             feats[i,j, 5] = hsvImg[i,j,2]\n",
    "#             feats[i,j, 6] = aprocHsvImg[i,j,0]\n",
    "#             feats[i,j, 7] = aprocHsvImg[i,j,1]\n",
    "#             feats[i,j, 8] = aprocHsvImg[i,j,2]\n",
    " \n",
    "#     return feats\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+7] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats2(filteredImg,hsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats3(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+3] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats4(filteredImg,hsvImg,aprocHsvImg): #\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "#     textTureFeatsLen = len(filteredImg)*3\n",
    "    extractedFeats = 3\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:   \n",
    "                    feats[i,j, step+3] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+4] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+5] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+7] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,2]       \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats5(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = hsvImg.shape[2]+aprocHsvImg.shape[2]\n",
    "    extractedFeats = 5\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                feats[i,j, step+3] = window.mean()\n",
    "                feats[i,j, step+4] = window.var()\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+5] = hsvImg[i,j,0]\n",
    "                    feats[i,j, step+6] = hsvImg[i,j,1]\n",
    "                    feats[i,j, step+7] = hsvImg[i,j,2]\n",
    "                    feats[i,j, step+8] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+9] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+10] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats6(filteredImg,hsvImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = 0\n",
    "#     textTureFeatsLen = len(filteredImg)*5\n",
    "    extractedFeats = 5\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    \n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                feats[i,j, step+3] = window.mean()\n",
    "                feats[i,j, step+4] = window.var()\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats7(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "    extractedFeats = 2\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "#                 feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+2] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+3] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mass_compute_and_combine_feats8(filteredImg,aprocHsvImg):\n",
    "    \n",
    "    coreFeatsLen = aprocHsvImg.shape[2]\n",
    "    extractedFeats = 4\n",
    "    textTureFeatsLen = len(filteredImg)*extractedFeats\n",
    "    dim = textTureFeatsLen+coreFeatsLen\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = window.mean()\n",
    "                feats[i,j, step+1] = window.var()\n",
    "                feats[i,j, step+2] = np.sum(window**2)\n",
    "                feats[i,j, step+3] =  np.sum(np.absolute(window))\n",
    "#                 feats[i,j, step+2] = image[i,j]\n",
    "                if step+extractedFeats == textTureFeatsLen:\n",
    "                    \n",
    "                    feats[i,j, step+4] = aprocHsvImg[i,j,0]\n",
    "                    feats[i,j, step+5] = aprocHsvImg[i,j,1]\n",
    "                    feats[i,j, step+6] = aprocHsvImg[i,j,2]\n",
    "                \n",
    "        step += extractedFeats\n",
    " \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def mass_compute_single_texture_feat(filteredImg,mode=\"var\"):\n",
    "    \n",
    "    dim =  len(filteredImg)\n",
    "    feats = np.zeros((filteredImg[0].shape[0],filteredImg[0].shape[1],dim))\n",
    "    step = 0\n",
    "    \n",
    "   \n",
    "    method = Esopagus_Compute_Texture_By_Mode(mode=mode)\n",
    "    \n",
    "    \n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-1,0):min(i+1,image.shape[0]-1),max(j-1,0):min(j+1,image.shape[1]-1)]\n",
    "                feats[i,j, step] = method.compute(window)\n",
    "        step += 1\n",
    " \n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mass_compute_single_color_feat(hsvImg,aprocHsvImg,mode=\"hsv\"):\n",
    "    \n",
    "    feats = np.zeros(hsvImg.shape)\n",
    "    step = 0\n",
    "    \n",
    "   \n",
    "    method = Esopagus_Compute_Color_By_Mode(mode=mode)\n",
    "    \n",
    "    for i in range(hsvImg.shape[0]):\n",
    "        for j in range(hsvImg.shape[1]):\n",
    "            feats[i,j] = method.compute(hsvImg,aprocHsvImg,i,j)\n",
    " \n",
    "    print \"color feats\"\n",
    "    print feats[10,10]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Esopagus_Compute_Texture_By_Mode:\n",
    "    def __init__(self, mode=\"var\"):\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == \"mean\":\n",
    "            self.compute = self.compute_mean\n",
    "        elif mode == \"var\":\n",
    "            self.compute = self.compute_var\n",
    "        elif mode == \"energy\":\n",
    "            self.compute = self.compute_local_energy\n",
    "        elif mode == \"amplitude\":\n",
    "            self.compute = self.compute_mean_amplitude\n",
    "    \n",
    "    def compute(self,window):\n",
    "        return 'ok'\n",
    "        \n",
    "    \n",
    "    def compute_mean(self,window):\n",
    "        return window.mean()\n",
    "    \n",
    "    def compute_var(self,window):\n",
    "        return window.var()\n",
    "    \n",
    "    def compute_local_energy(self,window):\n",
    "        return  np.sum(window**2)\n",
    "    \n",
    "    def compute_mean_amplitude(self,window):\n",
    "        return  np.sum(np.absolute(window))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Esopagus_Compute_Color_By_Mode:\n",
    "    def __init__(self, mode=\"hsv\"):\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == \"hsv\":\n",
    "            self.compute = self.compute_hsv\n",
    "        elif mode == \"approx-hsv\":\n",
    "            self.compute = self.compute_approx_hsv\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    def compute(self,window):\n",
    "        return 'ok'\n",
    "        \n",
    "    def compute_hsv(self,hsvImg,aprocHsvImg,i,j):\n",
    "        return hsvImg[i,j]\n",
    "    \n",
    "    def compute_approx_hsv(self,hsvImg,aprocHsvImg,i,j):\n",
    "        return aprocHsvImg[i,j]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(ref_white_img_feats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_img_feats(patchesName,which=1):\n",
    "    \n",
    "    \n",
    "    if patchesName == 'normal':   \n",
    "        targetImg = patches\n",
    "        targetImgHSV = patchesHsv\n",
    "    elif patchesName == 'white':\n",
    "        targetImg = whitePatches\n",
    "        targetImgHSV = whitePatchesHsv\n",
    "    elif patchesName == 'black':\n",
    "        targetImg = blackPatches\n",
    "        targetImgHSV = blackPatchesHsv\n",
    "    elif patchesName == 'lesion':\n",
    "        targetImg = lesionPatches\n",
    "        targetImgHSV = lesionPatchesHsv\n",
    "        \n",
    "    \n",
    "    ref_feats = {}\n",
    "\n",
    "    \n",
    "    for i in range(len(targetImgHSV)):\n",
    "        imgToFilter = rgb2gray(targetImg[i])\n",
    "        filtredImg = filterImage(imgToFilter,kernels)     \n",
    "        \n",
    "        if which ==1 :\n",
    "            ref_feats[i] = mass_compute_and_combine_feats(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "        elif which == 2:\n",
    "            ref_feats[i] =  mass_compute_and_combine_feats2(filtredImg,targetImgHSV[i])\n",
    "        elif which == 3:\n",
    "            ref_feats[i] =  mass_compute_and_combine_feats3(filtredImg,approximate(targetImgHSV[i]))\n",
    "        elif which == 4:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats4(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "\n",
    "        elif which == 5:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats5(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "\n",
    "        elif which == 6:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats6(filtredImg,targetImgHSV[i],approximate(targetImgHSV[i]))\n",
    "        elif which == 7:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats7(filtredImg,approximate(targetImgHSV[i]))\n",
    "        \n",
    "        elif which == 8:\n",
    "            ref_feats[i] = mass_compute_and_combine_feats8(filtredImg,approximate(targetImgHSV[i]))\n",
    "            \n",
    "            \n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ref_img_single_feats(patchesName,which=1,feats='texture'):\n",
    "    \n",
    "    \n",
    "    if patchesName == 'normal':   \n",
    "        targetImg = patches\n",
    "        targetImgHSV = patchesHsv\n",
    "    elif patchesName == 'white':\n",
    "        targetImg = whitePatches\n",
    "        targetImgHSV = whitePatchesHsv\n",
    "    elif patchesName == 'black':\n",
    "        targetImg = blackPatches\n",
    "        targetImgHSV = blackPatchesHsv\n",
    "    elif patchesName == 'lesion':\n",
    "        targetImg = lesionPatches\n",
    "        targetImgHSV = lesionPatchesHsv\n",
    "        \n",
    "    \n",
    "    ref_feats = {}\n",
    "    \n",
    "    if feats=='texture': \n",
    "        for i in range(len(targetImgHSV)):\n",
    "            imgToFilter = rgb2gray(targetImg[i])\n",
    "            filtredImg = filterImage(imgToFilter,kernels)\n",
    "            \n",
    "            ref_feats[i] = mass_compute_single_texture_feat(filtredImg, mode = texture_feats_names[which-1])\n",
    "            ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(targetImgHSV)):\n",
    "            ref_feats[i] =  mass_compute_single_color_feat(targetImgHSV[i],approximate(targetImgHSV[i]), mode= color_feats_names[which-1])\n",
    "            ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###k-means for features\n",
    "\n",
    "\n",
    "####k-means class\n",
    "\n",
    "\n",
    "\n",
    "class K_Means_Feats:\n",
    "    def __init__(self, k=10, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.rgbColors = np.array([[0,255,0],[255,255,255],[0,0,0],[255,0,0],[0,0,255],[255,255,0],[0,255,255],[255,0,255],[51,51,255],[102,102,0],[255,0,127],[160,32,240],[238,130,238]])\n",
    "        self.rgbColors.astype(float)\n",
    "#        white, green, ,red, yellow, purple,violet\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit(self,img,which=1):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ref_feats_n = ref_feats_dict[which-1][0]\n",
    "        ref_feats_w = ref_feats_dict[which-1][1]\n",
    "        ref_feats_b = ref_feats_dict[which-1][2]\n",
    "        ref_feats_l = ref_feats_dict[which-1][3]\n",
    "        \n",
    "        \n",
    "        #centroids for normal parts of the esophagus\n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "        #ramdomly select centroid for the lesions   \n",
    "#         self.centroids[self.k-1] = img[0,0,:]\n",
    "      \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1],3),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]:\n",
    "                \n",
    "                if  (cent < p_index): #normal pixels---assign green color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[0][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[0][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[0][2]\n",
    "                    \n",
    "                elif  (cent >= p_index) & (cent < w_p_index): #white pixels----assign white color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[1][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[1][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[1][2]\n",
    "                    \n",
    "                elif  (cent >= w_p_index) & (cent < b_p_index): # black pixels---assign black color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[2][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[2][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[2][2] \n",
    "                    \n",
    "                elif  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[3][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[3][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[3][2] \n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_and_filter(self,img):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "\n",
    "        ref_feats_n = ref_feats_normal\n",
    "        ref_feats_w = ref_feats_white\n",
    "        ref_feats_b = ref_feats_black\n",
    "        ref_feats_l = ref_feats_lesion\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "        \n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "            \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j,:]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j,:])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1]),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]: \n",
    "                if  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1]] = 255\n",
    "                    \n",
    "        return binary_opening(binary_opening(output, disk(3)),disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing Gabor filter bank kernels\n",
    "kernels = []\n",
    "for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "    for sigma in (1.0,1.5):  #gausian kernel window size\n",
    "#         for frequency in (0.1, 0.2):\n",
    "            kernel = np.real(gabor_kernel(0.15, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##prepare reference features\n",
    "# ref_feats_dict = {}\n",
    "\n",
    "# for i in range(8):\n",
    "#     ref_feats_dict[i]=[]\n",
    "#     ref_feats_dict[i].append(ref_img_feats('normal',which=i+1))\n",
    "#     ref_feats_dict[i].append(ref_img_feats('white',which=i+1))\n",
    "#     ref_feats_dict[i].append(ref_img_feats('black',which=i+1))\n",
    "#     ref_feats_dict[i].append(ref_img_feats('lesion',which=i+1))\n",
    "#     print i\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'Esopagus_Compute_By_Mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4b126405d88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mwhichfeat\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexture_feats_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_single_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhichfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_single_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhichfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mref_feats_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_img_single_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhichfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-4b777a64b460>\u001b[0m in \u001b[0;36mref_img_single_feats\u001b[0;34m(patchesName, which, feats)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfiltredImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilterImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgToFilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmass_compute_single_texture_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltredImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexture_feats_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2c61e0e1c53e>\u001b[0m in \u001b[0;36mmass_compute_single_texture_feat\u001b[0;34m(filteredImg, mode)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mEsopagus_Compute_By_Mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilteredImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'Esopagus_Compute_By_Mode' is not defined"
     ]
    }
   ],
   "source": [
    "ref_feats_dict = {}\n",
    "\n",
    "for i in range(len(texture_feats_names)+len(color_feats_names)):\n",
    "    \n",
    "    whichfeat=i+1\n",
    "    \n",
    "    if i<len(texture_feats_names):\n",
    "        mode = \"texture\"\n",
    "    else:\n",
    "        mode = \"color\"\n",
    "        whichfeat-=len(texture_feats_names)\n",
    "    ref_feats_dict[i]=[]\n",
    "    ref_feats_dict[i].append(ref_img_single_feats('normal',which=whichfeat,feats=mode))\n",
    "    ref_feats_dict[i].append(ref_img_single_feats('white',which=whichfeat,feats=mode))\n",
    "    ref_feats_dict[i].append(ref_img_single_feats('black',which=whichfeat,feats=mode))\n",
    "    ref_feats_dict[i].append(ref_img_single_feats('lesion',which=whichfeat,feats=mode))\n",
    "    print str(i) +\" -- \"+ mode +\" -- \"+  str(whichfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Best working ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colnum = 2+len(texture_feats_names)+len(color_feats_names)\n",
    "# rownum = int(math.floor((float(len(imgSamples))/ float(colnum))+1))\n",
    "rownum = len(imgSamples)\n",
    "# print(rownum)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*20), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lesionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    imgToFilter = rgb2gray(imgSamples[i])\n",
    "    \n",
    "    filtredImg = filterImage(imgToFilter,kernels)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "# ref_feats[i] = mass_compute_single_texture_feat(filtredImg,which = texture_feats_names[which-1])\n",
    "\n",
    "# ref_feats[i] =  mass_compute_single_color_feat(targetImgHSV[i],approximate(targetImgHSV[i]),which = color_feats_names[which-1])\n",
    "         \n",
    "   \n",
    "    \n",
    "    print(\"len(filtredImg) \")\n",
    "    print(len(filtredImg))\n",
    "    print(filtredImg[0].shape)\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i))\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i))\n",
    "    ax[index+1].axis('off')\n",
    "    \n",
    "    \n",
    "    for j in range(len(texture_feats_names)+len(color_feats_names)):\n",
    "        \n",
    "        \n",
    "    \n",
    "        whichfeat=j+1\n",
    "\n",
    "        if j<len(texture_feats_names):\n",
    "            mode = \"texture\"\n",
    "            title = texture_feats_names[whichfeat-1]\n",
    "            toSort = mass_compute_single_texture_feat(filtredImg,mode = texture_feats_names[whichfeat-1])\n",
    "        else:\n",
    "            mode = \"color\"\n",
    "            whichfeat-=len(texture_feats_names)\n",
    "            title = color_feats_names[whichfeat-1]\n",
    "            toSort =  mass_compute_single_color_feat(imgHsvSamples[i],approximate(imgHsvSamples[i]),mode = color_feats_names[whichfeat-1])\n",
    "            \n",
    "        ax[index+j+2].imshow(kmeanf.fit(toSort,which=j+1) ,cmap='gray')\n",
    "        ax[index+j+2].set_title(title+' - '+str(i))\n",
    "        ax[index+j+2].axis('off')\n",
    "\n",
    "         \n",
    "#     ax[index+2].imshow(kmeanf.fit(mass_compute_and_combine_feats(filtredImg,imgHsvSamples[i],approximate(imgHsvSamples[i])),which=1) ,cmap='gray')\n",
    "#     ax[index+2].set_title(\"both \"+str(i))\n",
    "#     ax[index+2].axis('off')\n",
    "    \n",
    "#     ax[index+3].imshow(kmeanf.fit(mass_compute_and_combine_feats7(filtredImg,imgHsvSamples[i]),which=7) ,cmap='gray')\n",
    "#     ax[index+3].set_title(\"both \"+str(i))\n",
    "#     ax[index+3].axis('off')\n",
    "    \n",
    "    \n",
    "#     ax[index+4].imshow(kmeanf.fit(mass_compute_and_combine_feats3(filtredImg,approximate(imgHsvSamples[i])),which=3) ,cmap='gray')\n",
    "#     ax[index+4].set_title(\"both \"+str(i))\n",
    "#     ax[index+4].axis('off')\n",
    "    \n",
    "#     ax[index+5].imshow(kmeanf.fit(mass_compute_and_combine_feats8(filtredImg,approximate(imgHsvSamples[i])),which=8) ,cmap='gray')\n",
    "#     ax[index+5].set_title(\"both \"+str(i))\n",
    "#     ax[index+5].axis('off')\n",
    "    \n",
    "    print \"img \"+str(i)+\"----done\"\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
