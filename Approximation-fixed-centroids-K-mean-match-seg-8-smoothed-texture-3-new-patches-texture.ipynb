{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from skimage import data,color, exposure,feature,io\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "import skimage.exposure as imexp\n",
    "from skimage.morphology import binary_opening,disk\n",
    "from skimage.filters import gabor_kernel\n",
    "from PIL import Image\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "(300, 300, 3)\n",
      "(100, 100, 3)\n",
      "(20, 20, 3)\n",
      "(20, 20, 3)\n",
      "(25, 25, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "imgSamples = [];\n",
    "imgHsvSamples = [];\n",
    "\n",
    "\n",
    "patches = [];\n",
    "patchesHsv = [];\n",
    "\n",
    "\n",
    "whitePatches = [];\n",
    "whitePatchesHsv = [];\n",
    "\n",
    "blackPatches = [];\n",
    "blackPatchesHsv = [];\n",
    "\n",
    "\n",
    "lesionPatches = [];\n",
    "lesionPatchesHsv = [];\n",
    "\n",
    "\n",
    "samplingSize =(300,300)\n",
    "#samplingMode = 'nearest'\n",
    "samplingMode = 'wrap'\n",
    "WINDOW_FRAME = 2\n",
    "gausssianSig = 0.4\n",
    "\n",
    "\n",
    "for i in range(0,15):\n",
    "    temp1= resize(np.array(Image.open('newSamples/'+str(i+1)+'.jpg')), samplingSize,mode=samplingMode)\n",
    "    image1 = img_as_float(temp1)\n",
    "    image1 = gaussian_filter(image1,gausssianSig)\n",
    "    imgSamples.append(image1)\n",
    "                      \n",
    "for i in range(len(imgSamples)):\n",
    "    imgHsvSamples.append(color.rgb2hsv(imgSamples[i]))\n",
    "    \n",
    "    \n",
    "for i in range(0,1):\n",
    "    \n",
    "    temp2= np.array(Image.open('newPatches4/normal'+str(i+1)+'.jpg'))\n",
    "    image2 = img_as_float(temp2)\n",
    "    image2 = gaussian_filter(image2, gausssianSig)\n",
    "    patches.append(image2)\n",
    "                      \n",
    "for i in range(len(patches)):\n",
    "    patchesHsv.append(color.rgb2hsv(patches[i]))\n",
    "    \n",
    "for i in range(0,1):\n",
    "    \n",
    "        \n",
    "    temp3= np.array(Image.open('newPatches4/white'+str(i+1)+'.jpg'))\n",
    "    image3 = img_as_float(temp3)\n",
    "    image3 = gaussian_filter(image3, gausssianSig)\n",
    "    whitePatches.append(image3)\n",
    "                      \n",
    "for i in range(len(whitePatches)):\n",
    "    whitePatchesHsv.append(color.rgb2hsv(whitePatches[i]))\n",
    "\n",
    "for i in range(0,1):\n",
    "    \n",
    "    temp4= np.array(Image.open('newPatches4/black'+str(i+1)+'.jpg'))\n",
    "    image4 = img_as_float(temp4)\n",
    "    image4 = gaussian_filter(image4,gausssianSig)\n",
    "    blackPatches.append(image4)\n",
    "    \n",
    "for i in range(len(blackPatches)):\n",
    "    blackPatchesHsv.append(color.rgb2hsv(blackPatches[i]))\n",
    "    \n",
    "for i in range(0,3):\n",
    "    \n",
    "    temp5=np.array(Image.open('newPatches4/lesion'+str(i+1)+'.jpg'))\n",
    "    image5 = img_as_float(temp5)\n",
    "    image5 = gaussian_filter(image5, gausssianSig)\n",
    "    lesionPatches.append(temp5)\n",
    "    \n",
    "for i in range(len(lesionPatches)):\n",
    "    lesionPatchesHsv.append(color.rgb2hsv(lesionPatches[i]))\n",
    "\n",
    "\n",
    "print(len(imgHsvSamples))  \n",
    "print(len(patchesHsv)) \n",
    "print(len(whitePatchesHsv)) \n",
    "print(len(blackPatchesHsv)) \n",
    "print(len(lesionPatches)) \n",
    "print(imgHsvSamples[0].shape)\n",
    "print(patchesHsv[0].shape)\n",
    "print(whitePatchesHsv[0].shape)\n",
    "print(blackPatchesHsv[0].shape)\n",
    "print(lesionPatchesHsv[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def satThreshold(v,s):    ##return hue or intensity as dominant feature\n",
    "    th = 1.0 - 0.8*v;\n",
    "    if(s>th):\n",
    "        return \"h\"\n",
    "    else: \n",
    "        return \"v\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate(img):\n",
    "    tmpImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            dominantVal = satThreshold(img[i,j,2],img[i,j,1])\n",
    "#             print(\"dominantVal----\"+dominantVal)\n",
    "            tmpImg[i,j,:] = img[i,j,:]\n",
    "            if dominantVal == \"h\":\n",
    "                tmpImg[i,j,0] = img[i,j,0]\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = 1.0\n",
    "                \n",
    "            else:\n",
    "                tmpImg[i,j,0] = 1.0\n",
    "                tmpImg[i,j,1] = 1.0\n",
    "                tmpImg[i,j,2] = img[i,j,2]\n",
    "        \n",
    "    return tmpImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gabor filter\n",
    "\n",
    "def filterImage(image, kernels):\n",
    "    filtered = []\n",
    "    for k, kernel in enumerate(kernels):\n",
    "        filtered.append(ndi.convolve(image, kernel, mode='wrap'))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mass_compute_texture_feat(img):\n",
    "\n",
    "    imgToFilter = rgb2gray(img)\n",
    "    filteredImg = filterImage(imgToFilter,kernels)\n",
    "    print \"filteredImg\"\n",
    "    print len(filteredImg)\n",
    "    \n",
    "    gaborEachFeats = 5\n",
    "    gaborFeatsLen = len(filteredImg)*gaborEachFeats\n",
    "    glcmFeats=2\n",
    "    dim = gaborFeatsLen+glcmFeats\n",
    "    \n",
    "    feats = np.zeros((img.shape[0],img.shape[1],dim))\n",
    "    step = 0\n",
    "\n",
    "    for m_index,image in enumerate(filteredImg):\n",
    "        for i in range(image.shape[0]):\n",
    "            for j in range(image.shape[1]):\n",
    "                window = image[max(i-WINDOW_FRAME,0):min(i+WINDOW_FRAME,image.shape[0]-1),max(j-WINDOW_FRAME,0):min(j+WINDOW_FRAME,image.shape[1]-1)]\n",
    "                \n",
    "                feats[i,j, step] = np.sum(window**2)\n",
    "                feats[i,j, step+1] =  np.sum(np.absolute(window))\n",
    "                feats[i,j, step+2] = image[i,j]\n",
    "                feats[i,j, step+3] = window.mean()\n",
    "                feats[i,j, step+4] = window.var()\n",
    "                \n",
    "        step += gaborEachFeats\n",
    "    \n",
    "    \n",
    "    for i in range(imgToFilter.shape[0]):\n",
    "        for j in range(imgToFilter.shape[1]):\n",
    "                window = imgToFilter[max(i-WINDOW_FRAME,0):min(i+WINDOW_FRAME,imgToFilter.shape[0]-1),max(j-WINDOW_FRAME,0):min(j+WINDOW_FRAME,imgToFilter.shape[1]-1)]\n",
    "                glcm = greycomatrix(window, [5], [0], 256, symmetric=True, normed=True)\n",
    "                feats[i,j, gaborFeatsLen] = greycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                feats[i,j, gaborFeatsLen+1] = greycoprops(glcm, 'correlation')[0, 0]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ref_img_feats(patchesName):\n",
    "    \n",
    "    \n",
    "    if patchesName == 'normal':   \n",
    "        targetImg = patches\n",
    "        targetImgHSV = patchesHsv\n",
    "    elif patchesName == 'white':\n",
    "        targetImg = whitePatches\n",
    "        targetImgHSV = whitePatchesHsv\n",
    "    elif patchesName == 'black':\n",
    "        targetImg = blackPatches\n",
    "        targetImgHSV = blackPatchesHsv\n",
    "    elif patchesName == 'lesion':\n",
    "        targetImg = lesionPatches\n",
    "        targetImgHSV = lesionPatchesHsv\n",
    "        \n",
    "    \n",
    "    ref_feats = {}\n",
    "\n",
    "    \n",
    "    for i in range(len(targetImgHSV)):\n",
    "       \n",
    "        ref_feats[i] = mass_compute_texture_feat(targetImg[i])\n",
    "            \n",
    "        ref_feats[i] = np.mean(ref_feats[i], axis=0)\n",
    "        \n",
    "#     print \"ref_feats\"\n",
    "#     print ref_feats\n",
    "    return ref_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###k-means for features\n",
    "\n",
    "\n",
    "####k-means class\n",
    "\n",
    "\n",
    "\n",
    "class K_Means_Feats:\n",
    "    def __init__(self, k=10, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.rgbColors = np.array([[0,255,0],[255,255,255],[0,0,0],[255,0,0],[0,0,255],[255,255,0],[0,255,255],[255,0,255],[51,51,255],[102,102,0],[255,0,127],[160,32,240],[238,130,238]])\n",
    "        self.rgbColors.astype(float)\n",
    "#        white, green, ,red, yellow, purple,violet\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def fit(self,img,which=1):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ref_feats_n = ref_feats_dict[which-1][0]\n",
    "        ref_feats_w = ref_feats_dict[which-1][1]\n",
    "        ref_feats_b = ref_feats_dict[which-1][2]\n",
    "        ref_feats_l = ref_feats_dict[which-1][3]\n",
    "        \n",
    "        \n",
    "        #centroids for normal parts of the esophagus\n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "        #ramdomly select centroid for the lesions   \n",
    "#         self.centroids[self.k-1] = img[0,0,:]\n",
    "\n",
    "\n",
    "#         print \"centroids----\"\n",
    "#         print self.centroids[0]\n",
    "#         print self.centroids\n",
    "      \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1],3),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "#         print \"last self.centroids\"\n",
    "#         print self.centroids\n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]:\n",
    "                \n",
    "                if  (cent < p_index): #normal pixels---assign green color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[0][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[0][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[0][2]\n",
    "                    \n",
    "                elif  (cent >= p_index) & (cent < w_p_index): #white pixels----assign white color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[1][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[1][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[1][2]\n",
    "                    \n",
    "                elif  (cent >= w_p_index) & (cent < b_p_index): # black pixels---assign black color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[2][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[2][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[2][2] \n",
    "                    \n",
    "                elif  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1],0] = self.rgbColors[3][0]\n",
    "                    output[pair[0],pair[1],1] = self.rgbColors[3][1]\n",
    "                    output[pair[0],pair[1],2] = self.rgbColors[3][2] \n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_and_filter(self,img):\n",
    "\n",
    "        self.centroids = {}\n",
    "        \n",
    "        tempImg = img\n",
    "\n",
    "        p_index = len(patches)\n",
    "        w_p_index = len(patches)+len(whitePatches)\n",
    "        b_p_index = len(patches)+len(whitePatches)+len(blackPatches)\n",
    "\n",
    "        ref_feats_n = ref_feats_normal\n",
    "        ref_feats_w = ref_feats_white\n",
    "        ref_feats_b = ref_feats_black\n",
    "        ref_feats_l = ref_feats_lesion\n",
    "            \n",
    "            \n",
    "        \n",
    "        print('indeces----')\n",
    "        print p_index\n",
    "        print w_p_index\n",
    "        \n",
    "        for i in range(len(patches)):\n",
    "            self.centroids[i] = ref_feats_n[i][0]\n",
    "        #centroids for white and bright parts\n",
    "        for i in range(len(whitePatches)):\n",
    "            self.centroids[p_index+i] = ref_feats_w[i][0]\n",
    "        #centroids for black parts\n",
    "        for i in range(len(blackPatches)):\n",
    "            self.centroids[w_p_index+i] = ref_feats_b[i][0] \n",
    "            \n",
    "        for i in range(len(lesionPatches)):\n",
    "            self.centroids[b_p_index+i] = ref_feats_l[i][0]     \n",
    "            \n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.clusters = {}\n",
    "            self.clustersIndeces = {}\n",
    "                ##classes holder\n",
    "            for i in range(self.k):\n",
    "                self.clusters[i] = []\n",
    "                self.clustersIndeces[i] = []\n",
    "        \n",
    "            for i in range(img.shape[0]):\n",
    "                for j in range(img.shape[1]):\n",
    "                    distances = [np.linalg.norm(img[i,j]-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                    clust_index = distances.index(min(distances))\n",
    "                    self.clustersIndeces[clust_index].append([i,j])\n",
    "                    self.clusters[clust_index].append(img[i,j])\n",
    "                    \n",
    "            prev_centroids = dict(self.centroids)         \n",
    "            \n",
    "            ##  re-assign centroids \n",
    "            for item in self.clusters:\n",
    "                self.centroids[item] = np.average(self.clusters[item],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/((original_centroid)*100.0)) > self.tol:\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "        \n",
    "        output = np.zeros((img.shape[0],img.shape[1]),np.uint8); \n",
    "        \n",
    "##assigning colors  \n",
    "\n",
    "        for cent in self.centroids:\n",
    "            for pair in self.clustersIndeces[cent]: \n",
    "                if  (cent >= b_p_index): #lesions------assign red color\n",
    "                    output[pair[0],pair[1]] = 255\n",
    "                    \n",
    "        return binary_opening(binary_opening(output, disk(3)),disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preparing Gabor filter bank kernels\n",
    "kernels = []\n",
    "for theta in np.arange(0, np.pi, np.pi / 6):\n",
    "    for sigma in (1.0,1.5):  #gausian kernel window size\n",
    "#         for frequency in (0.1, 0.2):\n",
    "            kernel = np.real(gabor_kernel(0.15, theta=theta,sigma_x=sigma, sigma_y=sigma))\n",
    "            kernels.append(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filteredImg\n",
      "12\n",
      "filteredImg\n",
      "12\n",
      "filteredImg\n",
      "12\n",
      "filteredImg\n",
      "12\n",
      "filteredImg\n",
      "12\n",
      "filteredImg\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "ref_feats_dict = {}\n",
    "\n",
    "i = 0\n",
    "ref_feats_dict[i]=[]\n",
    "ref_feats_dict[i].append(ref_img_feats('normal'))\n",
    "ref_feats_dict[i].append(ref_img_feats('white'))\n",
    "ref_feats_dict[i].append(ref_img_feats('black'))\n",
    "ref_feats_dict[i].append(ref_img_feats('lesion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Best working ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filteredImg\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "colnum = 3\n",
    "rownum = len(imgSamples)\n",
    "\n",
    "fig, axes = plt.subplots(rownum, colnum, figsize=(65, rownum*20), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "index = 0\n",
    "\n",
    "# divide into white, black, normal and abonomal parts of the esophagus\n",
    "kmeanf = K_Means_Feats(len(patches)+len(whitePatches)+len(blackPatches)+len(lesionPatches))\n",
    "\n",
    "for i in range(0, len(imgHsvSamples)):\n",
    "    \n",
    "    ax[index].imshow(imgSamples[i],cmap='gray')\n",
    "    ax[index].set_title(\"original rgb \"+str(i),fontsize=60)\n",
    "    ax[index].axis('off') \n",
    "   \n",
    "    ax[index+1].imshow(approximate(imgHsvSamples[i]),cmap='gray')\n",
    "    ax[index+1].set_title(\"segmented \"+str(i),fontsize=60)\n",
    "    ax[index+1].axis('off')\n",
    "    \n",
    "    ax[index+2].imshow(kmeanf.fit(mass_compute_texture_feat(imgHsvSamples[i]),which=1) ,cmap='gray')\n",
    "    ax[index+2].set_title(\"Texture Seg\"+' - '+str(i), fontsize=60)\n",
    "    ax[index+2].axis('off')\n",
    "    \n",
    "    index += colnum\n",
    "    \n",
    "    \n",
    "    print \"img \"+str(i)+\"----done\"\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
